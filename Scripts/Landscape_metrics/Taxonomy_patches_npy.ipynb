{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33553e4-eb1e-4da9-959a-fa978dc62ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Importar bibliotecas\n",
    "import os\n",
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np # Ainda precisamos do numpy para operações de CPU com Pandas\n",
    "import pandas as pd\n",
    "from cupyx.scipy.ndimage import binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cffc0c9-089c-4883-b317-749b26cbc532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório definido: E:\\Process\n"
     ]
    }
   ],
   "source": [
    "# 3. Definir caminhos e estrutura\n",
    "base_dir = r'E:\\Process'\n",
    "\n",
    "# Verificar se o diretório existe\n",
    "if not os.path.exists(base_dir):\n",
    "    print(f\"O diretório {base_dir} não existe.\")\n",
    "else:\n",
    "    print(f\"Diretório definido: {base_dir}\")\n",
    "\n",
    "# Structure for binary dilation - stays on GPU\n",
    "structure = cp.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]], dtype=cp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7ee98-a5c8-444a-95b8-7d7d66871c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. Funções de processamento otimizadas\n",
    "def analisar_vizinhança_gpu_vetorizado(patches_A_gpu, patches_B_gpu):\n",
    "    print(\"Iniciando análise de vizinhança na GPU (vetorizado)...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Obter IDs de patches únicos em patches_A, ignorando 0\n",
    "    patch_ids_A = cp.unique(patches_A_gpu[patches_A_gpu > 0])\n",
    "    total_patches = len(patch_ids_A)\n",
    "    print(f\"Total de patches únicos a analisar: {total_patches}\")\n",
    "\n",
    "    # Inicializar arrays para armazenar resultados na GPU\n",
    "    results_patch_id = cp.empty(total_patches, dtype=cp.int32)\n",
    "    results_vizinhanza = cp.empty(total_patches, dtype=cp.uint8)\n",
    "   \n",
    "    max_patch_id_A = int(patch_ids_A.max()) # Converte para int para evitar problemas com índices\n",
    "\n",
    "    # Mapa para armazenar os resultados\n",
    "    vizinhanza_map = cp.zeros(max_patch_id_A + 1, dtype=cp.uint8)\n",
    "\n",
    "    # Processar em blocos para gerenciar memória GPU e progresso\n",
    "    BLOCO_TAMANHO_GPU = 1000 # Ajuste este valor conforme a memória da GPU e o número de patches\n",
    "\n",
    "    for i in range(0, total_patches, BLOCO_TAMANHO_GPU):\n",
    "        bloco_ids = patch_ids_A[i : min(i + BLOCO_TAMANHO_GPU, total_patches)]\n",
    "        print(f\"  Processando bloco de patches {i+1} a {min(i + BLOCO_TAMANHO_GPU, total_patches)} de {total_patches} na GPU...\")\n",
    "\n",
    "    all_patch_ids_A = cp.unique(patches_A_gpu[patches_A_gpu > 0])\n",
    "    total_unique_patches = len(all_patch_ids_A)\n",
    "\n",
    "    # Prepare arrays para resultados, já na GPU\n",
    "    results_patch_ids = cp.empty(total_unique_patches, dtype=cp.int32)\n",
    "    results_vizinhanza = cp.empty(total_unique_patches, dtype=cp.uint8)\n",
    "\n",
    "       # Este é o principal ponto de otimização para seu caso.\n",
    "\n",
    "    for i, patch_id_val in enumerate(all_patch_ids_A):\n",
    "        # As operações abaixo são todas CuPy e rodam na GPU\n",
    "        mask_A = patches_A_gpu == patch_id_val\n",
    "        dilated = binary_dilation(mask_A, structure=structure)\n",
    "        border = cp.logical_and(dilated, ~mask_A)\n",
    "\n",
    "        neighbor_values = patches_B_gpu[border]\n",
    "        neighbor_ids = cp.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "        # Lógica de vizinhança (ainda serializada por patch_id, mas operando rápido na GPU)\n",
    "        viz = 0 # Inicializa com um valor padrão, caso nenhuma condição seja atendida\n",
    "        if len(neighbor_ids) == 0:\n",
    "            viz = 1\n",
    "        elif len(neighbor_ids) == 1:\n",
    "            # Atenção: cp.any e cp.all em CuPy operam em arrays CuPy.\n",
    "            # Se neighbor_values for um array CuPy, cp.any/cp.all funcionará.\n",
    "            if cp.any(neighbor_values == 0): # Verifica se há algum pixel \"estável\" (valor 0) na vizinhança\n",
    "                viz = 2\n",
    "            elif cp.all(neighbor_values == neighbor_ids[0]): # Verifica se todos os pixels de vizinhos são o mesmo ID\n",
    "                viz = 4\n",
    "            else: # Diferentes IDs na vizinhança, mas apenas um único neighbor_id (ex: 0 e um outro ID)\n",
    "                viz = 2\n",
    "        else: # Mais de um neighbor_id\n",
    "            viz = 3\n",
    "\n",
    "        results_patch_ids[i] = patch_id_val\n",
    "        results_vizinhanza[i] = viz\n",
    "\n",
    "        if (i + 1) % 1000 == 0: # Feedback de progresso\n",
    "            print(f\"  Processados {i+1} de {total_unique_patches} patches...\")\n",
    "            cp.cuda.Stream.null.synchronize() # Garante que as operações da GPU sejam concluídas para um tempo preciso\n",
    "\n",
    "    # Transferir os resultados finais da GPU para a CPU APENAS UMA VEZ\n",
    "    final_patch_ids = cp.asnumpy(results_patch_ids)\n",
    "    final_vizinhanza = cp.asnumpy(results_vizinhanza)\n",
    "\n",
    "    print(f\"Análise de vizinhança concluída em {time.time() - start_time:.2f} segundos.\")\n",
    "    return list(zip(final_patch_ids, final_vizinhanza))\n",
    "\n",
    "\n",
    "# 5. Verificar GPU (permanece o mesmo)\n",
    "print(\"GPU disponível:\", cp.cuda.Device(0).attributes.get('name', 'Nome não disponível'))\n",
    "cp.cuda.Device(0).use() # Garante que a GPU padrão seja usada\n",
    "\n",
    "# 6. Carregar arquivos .npy (permanece o mesmo, carregam diretamente para GPU)\n",
    "print(\"Carregando arquivos .npy para a GPU...\")\n",
    "ganho = cp.load(os.path.join(base_dir, 'ganho_patches_2013_2018.npy'))\n",
    "perda = cp.load(os.path.join(base_dir, 'perda_patches_2013_2018.npy'))\n",
    "estavel = cp.load(os.path.join(base_dir, 'estavel_patches_2013_2018.npy'))\n",
    "print(\"Arquivos .npy carregados.\")\n",
    "\n",
    "# 7. Executar análise com a função otimizada\n",
    "print(\"\\nAnalisando perda...\")\n",
    "resultado_perda = analisar_vizinhança_gpu_vetorizado(perda, estavel)\n",
    "\n",
    "print(\"\\nAnalisando ganho...\")\n",
    "resultado_ganho = analisar_vizinhança_gpu_vetorizado(ganho, estavel)\n",
    "\n",
    "\n",
    "# 8. Salvar resultados em CSV (permanece o mesmo)\n",
    "print(\"\\nSalvando resultados em CSV...\")\n",
    "df_perda = pd.DataFrame(resultado_perda, columns=['patch_id', 'vizinhança'])\n",
    "df_ganho = pd.DataFrame(resultado_ganho, columns=['patch_id', 'vizinhança'])\n",
    "\n",
    "# Verifique se o nome do arquivo de saída está correto (era 1985_1986, agora 1986_1987)\n",
    "df_perda.to_csv(os.path.join(base_dir, 'resultado_vizinhanca_perda_2013_2018.csv'), index=False)\n",
    "df_ganho.to_csv(os.path.join(base_dir, 'resultado_vizinhanca_ganho_2013_2018.csv'), index=False)\n",
    "\n",
    "print(\"Resultados salvos com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7154c85a-7f2b-462b-8a90-64a65f77cd44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: affine in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (2025.4.26)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: click-plugins in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from rasterio) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mario.barroso\\appdata\\local\\anaconda3\\lib\\site-packages (from click>=4.0->rasterio) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906cde1-66d3-46cb-9b03-0673ac15fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando conversão: resultado_vizinhanca_perda_2015_2016.csv\n",
      "Salvando GeoTIFF...\n",
      "GeoTIFF salvo: E:\\Process\\vizinhanca_perda_2015_2016.tif\n",
      "\n",
      "Iniciando conversão: resultado_vizinhanca_ganho_2015_2016.csv\n",
      "Salvando GeoTIFF...\n",
      "GeoTIFF salvo: E:\\Process\\vizinhanca_ganho_2015_2016.tif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.enums import Compression\n",
    "from rasterio.errors import RasterioIOError # Importar para tratar erros de I/O\n",
    "\n",
    "# Diretório base no Google Drive\n",
    "base_dir = r'E:\\Process'\n",
    "\n",
    "# Parâmetros do raster\n",
    "# Consistência nos nomes das variáveis (camelCase para snake_case, por convenção Python)\n",
    "COLS = 12989\n",
    "ROWS = 9278\n",
    "CELL_SIZE_X = 0.0002694945852358565\n",
    "CELL_SIZE_Y = 0.00026949458523585663\n",
    "UPPER_LEFT_X = -55.500254\n",
    "UPPER_LEFT_Y = -16.499806\n",
    "\n",
    "# Transformação geográfica\n",
    "transform = from_origin(UPPER_LEFT_X, UPPER_LEFT_Y, CELL_SIZE_X, CELL_SIZE_Y)\n",
    "\n",
    "# Sistema de coordenadas WGS 84 (EPSG:4326)\n",
    "CRS = 'EPSG:4326'\n",
    "\n",
    "# Função otimizada para converter CSV de vizinhança em GeoTIFF usando referência de patches\n",
    "def vizinhanca_para_geotiff_otimizado(csv_path, npy_patch_path, output_tif_path):\n",
    "    print(f\"Iniciando conversão: {os.path.basename(csv_path)}\")\n",
    "\n",
    "    try:\n",
    "        # Carregar CSV: usecols para carregar apenas as colunas necessárias, reduzindo o consumo de memória\n",
    "        df = pd.read_csv(csv_path, usecols=['patch_id', 'vizinhança'])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo CSV não encontrado em {csv_path}\")\n",
    "        return\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Erro: Arquivo CSV vazio ou mal formatado em {csv_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Carregar patches\n",
    "        patches = np.load(npy_patch_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo NPY não encontrado em {npy_patch_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar arquivo NPY {npy_patch_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Garantir que as dimensões de patches correspondam às esperadas\n",
    "    if patches.shape != (ROWS, COLS):\n",
    "        print(f\"Atenção: Dimensões do arquivo NPY ({patches.shape}) não correspondem às esperadas ({ROWS}, {COLS}).\")\n",
    "        # Você pode optar por redimensionar ou levantar um erro dependendo do comportamento desejado\n",
    "        # Ex: patches = np.resize(patches, (ROWS, COLS))\n",
    "\n",
    "    # Inicializar o raster de saída com zeros, usando o mesmo dtype dos valores de vizinhança ou np.uint8\n",
    "    # Se 'vizinhança' puder ter valores fora de uint8, ajuste o dtype (ex: np.int16)\n",
    "    # É crucial que raster_out tenha o mesmo tipo de dados do output GeoTIFF para eficiência\n",
    "    raster_out = np.zeros_like(patches, dtype=np.uint8) # Assumindo que 'vizinhança' cabe em uint8\n",
    "\n",
    "    # Otimização principal: Mapeamento vetorizado\n",
    "    # 1. Criar um array auxiliar para mapear patch_id para vizinhança\n",
    "    # Determine o valor máximo de patch_id para dimensionar o array de mapeamento\n",
    "    max_patch_id = df['patch_id'].max()\n",
    "    if max_patch_id >= (2**32 - 1): # Se patch_id for muito grande, usar um dicionário pode ser melhor\n",
    "        print(\"Atenção: patch_id muito grande, usando dicionário para mapeamento.\")\n",
    "        patch_id_to_vizinhanza = dict(zip(df['patch_id'], df['vizinhança']))\n",
    "        # Iterar sobre os patches e aplicar o mapeamento\n",
    "        for i in np.unique(patches): # Itera sobre os IDs de patches únicos presentes no raster\n",
    "            if i in patch_id_to_vizinhanza:\n",
    "                raster_out[patches == i] = patch_id_to_vizinhanza[i]\n",
    "    else:\n",
    "        # Cria um array de lookup onde o índice é o patch_id e o valor é a vizinhança\n",
    "        # Inicializa com 0 (ou um valor de 'no data' apropriado)\n",
    "        lookup_table = np.zeros(max_patch_id + 1, dtype=np.uint8)\n",
    "        # Preenche a lookup table com os valores de vizinhança\n",
    "        lookup_table[df['patch_id'].values] = df['vizinhança'].values\n",
    "\n",
    "        # Aplica o mapeamento vetorizado: para cada pixel em 'patches', use seu valor como índice na lookup_table\n",
    "        # Isso é SIGNIFICATIVAMENTE mais rápido do que o loop original.\n",
    "        raster_out = lookup_table[patches]\n",
    "\n",
    "    print(\"Salvando GeoTIFF...\")\n",
    "    try:\n",
    "        with rasterio.open(\n",
    "            output_tif_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=ROWS,\n",
    "            width=COLS,\n",
    "            count=1,\n",
    "            dtype=raster_out.dtype, # Usa o dtype do array de saída\n",
    "            crs=CRS,\n",
    "            transform=transform,\n",
    "            compress=Compression.lzw, # Compressão LZW é lossless e eficiente\n",
    "            tiled=True,              # Ativa o tiling para melhor performance de leitura/escrita em arquivos grandes\n",
    "            blockxsize=256,          # Tamanho do bloco para tiling (ajustar se necessário)\n",
    "            blockysize=256           # Tamanho do bloco para tiling\n",
    "        ) as dst:\n",
    "            dst.write(raster_out, 1)\n",
    "        print(f\"GeoTIFF salvo: {output_tif_path}\\n\")\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Erro de I/O ao salvar GeoTIFF {output_tif_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao salvar GeoTIFF {output_tif_path}: {e}\")\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "csv_perda = os.path.join(base_dir, 'resultado_vizinhanca_perda_2013_2018.csv')\n",
    "csv_ganho = os.path.join(base_dir, 'resultado_vizinhanca_ganho_2013_2018.csv')\n",
    "npy_perda = os.path.join(base_dir, 'perda_patches_2013_2018.npy')\n",
    "npy_ganho = os.path.join(base_dir, 'ganho_patches_2013_2018.npy')\n",
    "tif_perda = os.path.join(base_dir, 'vizinhanca_perda_2013_2018.tif')\n",
    "tif_ganho = os.path.join(base_dir, 'vizinhanca_ganho_2013_2018.tif')\n",
    "\n",
    "# Executar conversão com a função otimizada\n",
    "vizinhanca_para_geotiff_otimizado(csv_perda, npy_perda, tif_perda)\n",
    "vizinhanca_para_geotiff_otimizado(csv_ganho, npy_ganho, tif_ganho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957b9cb-cd57-4640-8530-453ccbfdfd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
