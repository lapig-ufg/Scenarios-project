{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ef6ab-f99d-4f94-9fb9-a7e93201870c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517a612-fe80-4c44-9ecc-147a33623d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Path having the raster files\n",
    "directory = r\"E:\\Process\"\n",
    "\n",
    "# Function to apply the comparison rule between two arrays\n",
    "def compare_rasters(arr1, arr2):\n",
    "    result = np.zeros_like(arr1, dtype=np.uint8)\n",
    "    result[(arr1 == 1) & (arr2 == 1)] = 1\n",
    "    result[(arr1 == 1) & (arr2 == 0)] = 2\n",
    "    result[(arr1 == 0) & (arr2 == 1)] = 3\n",
    "    return result\n",
    "\n",
    "# Loop through the years from 1985 to 2022 to compare with the following year\n",
    " \n",
    "for year in range(2014, 2016):\n",
    "    file1 = os.path.join(directory, f\"base{year}.tif\")\n",
    "    file2 = os.path.join(directory, f\"base{year+1}.tif\")\n",
    "    output = os.path.join(directory, f\"comparacao_{year}_{year+1}.tif\")\n",
    "\n",
    "    print(f\"Comparing {file1} with {file2}...\")\n",
    "\n",
    "    with rasterio.open(file1) as src1, rasterio.open(file2) as src2:\n",
    "        arr1 = src1.read(1)\n",
    "        arr2 = src2.read(1)\n",
    "        profile = src1.profile\n",
    "\n",
    "        result = compare_rasters(arr1, arr2)\n",
    "\n",
    "        profile.update(dtype=rasterio.uint8, count=1, nodata=255)\n",
    "        with rasterio.open(saida, 'w', **perfil) as dst:\n",
    "            dst.write(result, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e759f8-c0fc-4033-888d-0d7c6d70fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae04198-837d-4001-abf5-654500f05c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Directory containing the comparison files\n",
    "directory = r\"E:\\Process\"\n",
    "\n",
    "# Rook connectivity structure (4-neighbors)\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "# Function to save raster based on a mask\n",
    "def save_raster_mask(mask, profile, output_path):\n",
    "    profile.update(dtype=rasterio.uint8, count=1, nodata=0)\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(mask.astype(np.uint8), 1)\n",
    "# Process all comparison files\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"comparacao_\") and file_name.endswith(\".tif\"):\n",
    "        path = os.path.join(directory, file_name)\n",
    "        print(f\"Processing {file_name}...\")\n",
    "\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1)\n",
    "            profile = src.profile\n",
    "            # Extract years from the file name\n",
    "            parts = file_name.replace(\".tif\", \"\").split(\"_\")\n",
    "            year1, year2 = parts[1], parts[2]\n",
    "\n",
    "            # Separate classes\n",
    "            for classe, nome in zip([1, 2, 3], ['estavel', 'perda', 'ganho']):\n",
    "                mask = (data == classe).astype(np.uint8)\n",
    "                output_path = os.path.join(directory, f\"{nome}_{year1}_{year2}.tif\")\n",
    "                save_raster_mask(mask, profile, output_path)\n",
    "                print(f\"  File {nome} saved: {output_path}\")\n",
    "\n",
    "                # Identify connected patches\n",
    "                binary_mask = mask > 0\n",
    "                labeled_array, num_features = label(binary_mask, structure=structure)\n",
    "\n",
    "                # Save labeled raster\n",
    "                labeled_path = os.path.join(directory, f\"{name}_patches_{year1}_{year2}.tif\")\n",
    "                profile.update(dtype=rasterio.int32, nodata=0)\n",
    "                with rasterio.open(labeled_path, 'w', **profile) as dst:\n",
    "                    dst.write(labeled_array.astype(np.int32), 1)\n",
    "                print(f\"  Labeled patches saved: {labeled_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f452c1-2184-4e4e-88b0-c88764606cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import binary_dilation\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Directory containing the patch files\n",
    "directory = r\"E:\\Projetos\\GeoFM\\Patches\"\n",
    "\n",
    "# Rook connectivity structure (4-neighbors)\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "# Function to load raster\n",
    "def load_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        return src.read(1)\n",
    "\n",
    "# Function to calculate neighborhood between patches of A and B\n",
    "def analyze_neighborhood(patches_A, patches_B):\n",
    "    result = []\n",
    "    patch_ids_A = np.unique(patches_A)\n",
    "    patch_ids_A = patch_ids_A[patch_ids_A > 0]  # Ignore background\n",
    "    for i, patch_id in enumerate(patch_ids_A):\n",
    "        mask_A = patches_A == patch_id\n",
    "        dilated = binary_dilation(mask_A, structure=structure)\n",
    "        border = np.logical_and(dilated, ~mask_A)\n",
    "\n",
    "        neighbor_values = patches_B[border]\n",
    "        neighbor_ids = np.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "        if len(neighbor_ids) == 0:\n",
    "            viz = 1\n",
    "        elif len(neighbor_ids) == 1:\n",
    "            if 0 in neighbor_values:\n",
    "                viz = 2\n",
    "            elif np.all(neighbor_values == neighbor_ids[0]):\n",
    "                viz = 4\n",
    "            else:\n",
    "                viz = 2\n",
    "        else:\n",
    "            viz = 3\n",
    "\n",
    "        result.append((int(patch_id), viz))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Dictionary to store the results\n",
    "neighborhood_results = defaultdict(list)\n",
    "\n",
    "# Process pairs of loss/stable and gain/stable files\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"perda_patches_\") and file_name.endswith(\".tif\"):\n",
    "        parts = file_name.replace(\".tif\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        loss_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.tif\")\n",
    "\n",
    "        patches_A = load_raster(loss_path)\n",
    "        patches_B = load_raster(stable_path)\n",
    "\n",
    "        result = analyze_neighborhood(patches_A, patches_B)\n",
    "        neighborhood_results[f\"loss_{year1}_{year2}\"] = result\n",
    "\n",
    "    elif file_name.startswith(\"ganho_patches_\") and file_name.endswith(\".tif\"):\n",
    "        parts = file_name.replace(\".tif\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        gain_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.tif\")\n",
    "\n",
    "        patches_A = load_raster(gain_path)\n",
    "        patches_B = load_raster(stable_path)\n",
    "\n",
    "        result = analyze_neighborhood(patches_A, patches_B)\n",
    "        neighborhood_results[f\"gain_{year1}_{year2}\"] = result\n",
    "\n",
    "# Example of result visualization\n",
    "for key, lst in neighborhood_results.items():\n",
    "    print(f\"{key}: {len(lst)} patches analyzed\")\n",
    "    print(\"Example:\", lst[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918919e-563c-4cbf-a990-22aa11dde03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import binary_dilation\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory containing the patch files\n",
    "directory = r\"E:\\Projetos\\GeoFM\\Patches\"\n",
    "\n",
    "# Rook connectivity structure (4-neighbors)\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "# Function to load raster\n",
    "def load_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        return src.read(1)\n",
    "\n",
    "# Function to calculate neighborhood between patches of A and B in blocks\n",
    "def analyze_neighborhood_in_blocks(patches_A, patches_B, block_size=5000):\n",
    "    result = []\n",
    "    patch_ids_A = np.unique(patches_A)\n",
    "    patch_ids_A = patch_ids_A[patch_ids_A > 0]  # Ignore background\n",
    "    total = len(patch_ids_A)\n",
    "\n",
    "    for start in range(0, total, block_size):\n",
    "        end = min(start + block_size, total)\n",
    "        block_ids = patch_ids_A[start:end]\n",
    "        print(f\"Processing patch blocks {start+1} to {end} of {total}...\")\n",
    "\n",
    "        for patch_id in block_ids:\n",
    "            mask_A = patches_A == patch_id\n",
    "            dilated = binary_dilation(mask_A, structure=structure)\n",
    "            border = np.logical_and(dilated, ~mask_A)\n",
    "\n",
    "            neighbor_values = patches_B[border]\n",
    "            neighbor_ids = np.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "            if len(neighbor_ids) == 0:\n",
    "                viz = 1\n",
    "            elif len(neighbor_ids) == 1:\n",
    "                if 0 in neighbor_values:\n",
    "                    viz = 2\n",
    "                elif np.all(neighbor_values == neighbor_ids[0]):\n",
    "                    viz = 4\n",
    "                else:\n",
    "                    viz = 2\n",
    "            else:\n",
    "                viz = 3\n",
    "\n",
    "            result.append((int(patch_id), viz))\n",
    "\n",
    "    return result   \n",
    "\n",
    "# Dictionary to store the results\n",
    "neighborhood_results = defaultdict(list)\n",
    "\n",
    "# Process pairs of loss/stable and gain/stable files\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"perda_patches_\") and file_name.endswith(\".tif\"):\n",
    "        parts = file_name.replace(\".tif\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        loss_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.tif\")\n",
    "\n",
    "        patches_A = load_raster(loss_path)\n",
    "        patches_B = load_raster(stable_path)\n",
    "        result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "        neighborhood_results[f\"loss_{year1}_{year2}\"] = result\n",
    "\n",
    "    elif file_name.startswith(\"ganho_patches_\") and file_name.endswith(\".tif\"):\n",
    "        parts = file_name.replace(\".tif\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        gain_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.tif\")\n",
    "\n",
    "        patches_A = load_raster(gain_path)\n",
    "        patches_B = load_raster(stable_path)\n",
    "\n",
    "        result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "        neighborhood_results[f\"gain_{year1}_{year2}\"] = result\n",
    "# Example of result visualization\n",
    "for key, lst in neighborhood_results.items():\n",
    "    print(f\"{key}: {len(lst)} patches analyzed\")\n",
    "    print(\"Example:\", lst[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544dabc-84e8-4e48-9d24-b57baba147ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "directory = r\"E:\\Process\"\n",
    "\n",
    "print(\"Converting GeoTIFF files to .npy...\")\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.endswith(\".tif\") and \"_patches_\" in file_name:\n",
    "        tif_path = os.path.join(directory, file_name)\n",
    "        npy_path = os.path.join(directory, file_name.replace(\".tif\", \".npy\"))\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            array = src.read(1)\n",
    "            np.save(npy_path, array)\n",
    "        print(f\"  Converted: {file_name} -> {os.path.basename(npy_path)}\")\n",
    "print(\"Conversion completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6af47-f4a1-436f-add6-b6d258efb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation\n",
    "from collections import defaultdict\n",
    "\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "def analyze_neighborhood_in_blocks(patches_A, patches_B, block_size=5000):\n",
    "    result = []\n",
    "    patch_ids_A = np.unique(patches_A)\n",
    "    patch_ids_A = patch_ids_A[patch_ids_A > 0]\n",
    "    total = len(patch_ids_A)\n",
    "\n",
    "    for start in range(0, total, block_size):\n",
    "        end = min(start + block_size, total)\n",
    "        block_ids = patch_ids_A[start:end]\n",
    "        print(f\"  Processing patch blocks {start+1} to {end} of {total}...\")\n",
    "\n",
    "        for patch_id in block_ids:\n",
    "            mask_A = patches_A == patch_id\n",
    "            dilated = binary_dilation(mask_A, structure=structure)\n",
    "            border = np.logical_and(dilated, ~mask_A)\n",
    "\n",
    "            neighbor_values = patches_B[border]\n",
    "            neighbor_ids = np.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "            if len(neighbor_ids) == 0:\n",
    "                viz = 1\n",
    "            elif len(neighbor_ids) == 1:\n",
    "                if 0 in neighbor_values:\n",
    "                    viz = 2\n",
    "                elif np.all(neighbor_values == neighbor_ids[0]):\n",
    "                    viz = 4\n",
    "                else:\n",
    "                    viz = 2\n",
    "            else:\n",
    "                viz = 3\n",
    "\n",
    "            result.append((int(patch_id), viz))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Execute analysis\n",
    "neighborhood_results = defaultdict(list)\n",
    "\n",
    "print(\"Starting neighborhood analysis with .npy files...\\n\")\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"perda_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        loss_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = np.load(loss_path)\n",
    "            patches_B = np.load(stable_path)\n",
    "            print(f\"Analyzing loss_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "            neighborhood_results[f\"loss_{year1}_{year2}\"] = result\n",
    "\n",
    "    elif file_name.startswith(\"ganho_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        gain_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = np.load(gain_path)\n",
    "            patches_B = np.load(stable_path)\n",
    "            print(f\"Analyzing gain_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "            neighborhood_results[f\"gain_{year1}_{year2}\"] = result\n",
    "\n",
    "print(\"\\nNeighborhood analysis completed.\")\n",
    "for key, lst in neighborhood_results.items():\n",
    "    print(f\"{key}: {len(lst)} patches analyzed. Example: {lst[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cd70d-3e50-4bcf-ba2d-cba50105a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from skimage.morphology import binary_dilation\n",
    "\n",
    "\n",
    "\n",
    "# Directory containing the .npy files\n",
    "directory = r\"E:\\Projetos\\GeoFM\\Patches\"\n",
    "\n",
    "# Rook connectivity structure (4-neighbors)\n",
    "structure = np.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "# Function to process a single patch\n",
    "def process_patch(patch_id, patches_A, patches_B):\n",
    "    mask_A = patches_A == patch_id\n",
    "    dilated = binary_dilation(mask_A, footprint=structure)\n",
    "    border = np.logical_and(dilated, ~mask_A)\n",
    "\n",
    "    neighbor_values = patches_B[border]\n",
    "    neighbor_ids = np.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "    if len(neighbor_ids) == 0:\n",
    "        viz = 1\n",
    "    elif len(neighbor_ids) == 1:\n",
    "        if 0 in neighbor_values:\n",
    "            viz = 2\n",
    "        elif np.all(neighbor_values == neighbor_ids[0]):\n",
    "            viz = 4\n",
    "        else:\n",
    "            viz = 2\n",
    "    else:\n",
    "        viz = 3\n",
    "\n",
    "    return (int(patch_id), viz)\n",
    "\n",
    "# Function to process blocks of patches with parallelism\n",
    "def analyze_neighborhood_in_blocks(patches_A, patches_B, block_size=5000):\n",
    "    result = []\n",
    "    patch_ids_A = np.unique(patches_A)\n",
    "    patch_ids_A = patch_ids_A[patch_ids_A > 0]\n",
    "    total = len(patch_ids_A)\n",
    "\n",
    "    for start in range(0, total, block_size):\n",
    "        end = min(start + block_size, total)\n",
    "        block_ids = patch_ids_A[start:end]\n",
    "        print(f\"  Processing patch blocks {start+1} to {end} of {total}...\")\n",
    "        block_start = time.time()\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            args = ((patch_id, patches_A, patches_B) for patch_id in block_ids)\n",
    "            block_result = list(executor.map(lambda p: process_patch(*p), args))\n",
    "\n",
    "        result.extend(block_result)\n",
    "        print(f\"    Time for block: {time.time() - block_start:.2f} seconds\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Execute analysis\n",
    "neighborhood_results = defaultdict(list)\n",
    "\n",
    "print(\"Starting neighborhood analysis with .npy files...\\n\")\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"perda_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        loss_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = np.load(loss_path)\n",
    "            patches_B = np.load(stable_path)\n",
    "            print(f\"Analyzing loss_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "            neighborhood_results[f\"loss_{year1}_{year2}\"] = result\n",
    "\n",
    "    elif file_name.startswith(\"ganho_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        gain_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = np.load(gain_path)\n",
    "            patches_B = np.load(stable_path)\n",
    "            print(f\"Analyzing gain_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks(patches_A, patches_B)\n",
    "            neighborhood_results[f\"gain_{year1}_{year2}\"] = result\n",
    "\n",
    "print(\"\\nNeighborhood analysis completed.\")\n",
    "for key, patch_list in neighborhood_results.items():\n",
    "    print(f\"{key}: {len(patch_list)} patches analyzed. Example: {patch_list[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528b6e9-860b-4fd5-8879-6c24f6bdc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cupy-cuda12x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a88b0-41ba-4e43-8588-aeed78cdc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "print(\"NNumber of available GPUs:\", cp.cuda.runtime.getDeviceCount())\n",
    "print(\"GPU name:\", cp.cuda.Device(0).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27253f7-55bc-408a-95e5-f91491bce200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from cupyx.scipy.ndimage import binary_dilation\n",
    "\n",
    "# Directory containing the .npy files\n",
    "directory = r\"E:\\Process\"\n",
    "\n",
    "# Rook connectivity structure (4-neighbors) in CuPy\n",
    "structure = cp.array([[0, 1, 0],\n",
    "                      [1, 1, 1],\n",
    "                      [0, 1, 0]], dtype=cp.uint8)\n",
    "\n",
    "# Function to process a single patch on the GPU\n",
    "def process_patch_gpu(patch_id, patches_A_gpu, patches_B_gpu):\n",
    "    mask_A = patches_A_gpu == patch_id\n",
    "    dilated = binary_dilation(mask_A, structure=structure)\n",
    "    border = cp.logical_and(dilated, ~mask_A)\n",
    "\n",
    "    neighbor_values = patches_B_gpu[border]\n",
    "    neighbor_ids = cp.unique(neighbor_values[neighbor_values > 0])\n",
    "\n",
    "    if len(neighbor_ids) == 0:\n",
    "        viz = 1\n",
    "    elif len(neighbor_ids) == 1:\n",
    "        if cp.any(neighbor_values == 0):\n",
    "            viz = 2\n",
    "        elif cp.all(neighbor_values == neighbor_ids[0]):\n",
    "            viz = 4\n",
    "        else:\n",
    "            viz = 2\n",
    "    else:\n",
    "        viz = 3\n",
    "\n",
    "    return int(patch_id), viz\n",
    "\n",
    "# Function to process blocks of patches with parallelism\n",
    "def analyze_neighborhood_in_blocks_gpu(patches_A, patches_B, block_size=5000):\n",
    "    result = []\n",
    "    patch_ids_A = cp.unique(patches_A)\n",
    "    patch_ids_A = patch_ids_A[patch_ids_A > 0]\n",
    "    total = len(patch_ids_A)\n",
    "\n",
    "    for start in range(0, total, block_size):\n",
    "        end = min(start + block_size, total)\n",
    "        block_ids = patch_ids_A[start:end]\n",
    "        print(f\"  Processing patch blocks {start+1} to {end} of {total}...\")\n",
    "        block_start = time.time()\n",
    "        # Transfer block of IDs to CPU for parallelism\n",
    "        block_ids_cpu = cp.asnumpy(block_ids)\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            args = ((patch_id, patches_A, patches_B) for patch_id in block_ids_cpu)\n",
    "            block_result = list(executor.map(lambda p: process_patch_gpu(*p), args))\n",
    "\n",
    "        result.extend(block_result)\n",
    "        print(f\"    Time for block: {time.time() - block_start:.2f} seconds\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Execute analysis\n",
    "neighborhood_results = defaultdict(list)\n",
    "\n",
    "print(\"Starting neighborhood analysis with CuPy and GPU...\\n\")\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.startswith(\"perda_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        loss_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = cp.load(loss_path)\n",
    "            patches_B = cp.load(stable_path)\n",
    "            print(f\"Analyzing loss_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks_gpu(patches_A, patches_B)\n",
    "            neighborhood_results[f\"loss_{year1}_{year2}\"] = result\n",
    "\n",
    "    elif file_name.startswith(\"ganho_patches_\") and file_name.endswith(\".npy\"):\n",
    "        parts = file_name.replace(\".npy\", \"\").split(\"_\")\n",
    "        year1, year2 = parts[2], parts[3]\n",
    "        gain_path = os.path.join(directory, file_name)\n",
    "        stable_path = os.path.join(directory, f\"estavel_patches_{year1}_{year2}.npy\")\n",
    "        if os.path.exists(stable_path):\n",
    "            patches_A = cp.load(gain_path)\n",
    "            patches_B = cp.load(stable_path)\n",
    "            print(f\"Analyzing gain_{year1}_{year2}...\")\n",
    "            result = analyze_neighborhood_in_blocks_gpu(patches_A, patches_B)\n",
    "            neighborhood_results[f\"gain_{year1}_{year2}\"] = result\n",
    "\n",
    "print(\"\\nNeighborhood analysis completed.\")\n",
    "for key, lst in neighborhood_results.items():\n",
    "    print(f\"{key}: {len(lst)} patches analyzed. Example: {lst[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee063c98-d351-415f-bdf6-c8d1e3db4af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
